{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "010afd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Node to store value\n",
    "class Node:\n",
    "    def __init__(self, val, parents=(), operation=None):\n",
    "        self.val = val\n",
    "        self.grad = 0.0\n",
    "        self._backward = lambda : None\n",
    "        self.parents = set(parents)\n",
    "        self.op = operation\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.val)\n",
    "    \n",
    "    def __mul__(self, operand):\n",
    "        operand = Node(operand) if not isinstance(operand, Node) else operand\n",
    "        out = Node(self.val * operand.val, (self, operand), operation=\"*\")\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += operand.val * out.grad\n",
    "            operand.grad += self.val * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __rmul__(self, operand):\n",
    "        return self * operand\n",
    "    \n",
    "    def __add__(self, operand):\n",
    "        operand = Node(operand) if not isinstance(operand, Node) else operand\n",
    "        out = Node(self.val + operand.val, (self, operand), operation=\"+\")\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += 1.0 * out.grad\n",
    "            operand.grad += 1.0 * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __radd__(self, operand):\n",
    "        return self + operand\n",
    "    \n",
    "    def __neg__(self): \n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, other): \n",
    "        return self + (-other)\n",
    "    \n",
    "    def __rsub__(self, other): \n",
    "        return other + (-self)\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        out = Node(self.val**other, (self,), \"pow\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (other * self.val**(other-1)) * out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "        \n",
    "    \n",
    "    def tanh(self):\n",
    "        out = Node((math.exp(2 * self.val) - 1) / (math.exp(2 * self.val) + 1), (self,), \"tanh\")\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += (1 - out.val**2) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def backward(self):\n",
    "        \n",
    "        topo_order = []\n",
    "        visited = set()\n",
    "        \n",
    "        self.grad = 1.0\n",
    "        def topo_sort(self):\n",
    "            if self in visited:\n",
    "                return \n",
    "            visited.add(self)\n",
    "            for parent in self.parents:\n",
    "                topo_sort(parent)\n",
    "            topo_order.append(self)\n",
    "        topo_sort(self)\n",
    "        \n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo_order):\n",
    "            node._backward()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "17abcb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Line equation\n",
    "# w = Node(2)\n",
    "# x = Node(3)\n",
    "# c = Node(6)\n",
    "\n",
    "# def f(x):\n",
    "#     return w.val * x.val + c.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "e6a0d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gradient calculation\n",
    "# h = Node(0.0000001)\n",
    "# delta_x = x + h\n",
    "# dy_dx = (f(delta_x) - f(x)) / h.val\n",
    "# dy_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "7074f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialize weights and biases\n",
    "\n",
    "w1 = Node(random.random())\n",
    "w2 = Node(random.random())\n",
    "c1 = Node(random.random())\n",
    "c2 = Node(random.random())\n",
    "\n",
    "# Inputs\n",
    "x1 = Node(4.0)\n",
    "x2 = Node(-6.0)\n",
    "\n",
    "w1x1 = w1 * x1\n",
    "y1 = w1x1 + c1\n",
    "w2x2 = w2 * x2\n",
    "y2 = w2x2 + c2\n",
    "y = y1 + y2\n",
    "z = y.tanh()\n",
    "\n",
    "# y._backward()\n",
    "# y2._backward()\n",
    "# y1._backward()\n",
    "# w2x2._backward()\n",
    "# w1x1._backward()\n",
    "\n",
    "# z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "9bf611d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4658688525582094"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "a2a345f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "9a3f8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pytorch\n",
    "import torch\n",
    "\n",
    "torch_x1 = torch.tensor(x1.val)\n",
    "torch_x2 = torch.tensor(x2.val)\n",
    "torch_w1 = torch.tensor(w1.val)\n",
    "torch_w2 = torch.tensor(w2.val)\n",
    "torch_c1 = torch.tensor(c1.val)\n",
    "torch_c2 = torch.tensor(c2.val)\n",
    "\n",
    "torch_x1.requires_grad = True\n",
    "torch_x2.requires_grad = True\n",
    "torch_w1.requires_grad = True\n",
    "torch_w2.requires_grad = True\n",
    "torch_c1.requires_grad = True\n",
    "torch_c2.requires_grad = True\n",
    "\n",
    "torch_y = (torch_w1 * torch_x1 + torch_c1) + (torch_w2 * torch_x2 + torch_c2)\n",
    "torch_z = torch.tanh(torch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "ce7631ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4658688525582094"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "b8e1ba6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4659, grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "6e7f9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "a1da1e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6867)\n",
      "0.6867285883899293\n",
      "tensor(0.5757)\n",
      "0.5757186002670746\n",
      "tensor(3.1319)\n",
      "3.131864848864389\n",
      "tensor(-4.6978)\n",
      "-4.697797273296584\n",
      "tensor(0.7830)\n",
      "0.7829662122160973\n",
      "tensor(0.7830)\n",
      "0.7829662122160973\n"
     ]
    }
   ],
   "source": [
    "print(torch_x1.grad)\n",
    "print(x1.grad)\n",
    "print(torch_x2.grad)\n",
    "print(x2.grad)\n",
    "print(torch_w1.grad)\n",
    "print(w1.grad)\n",
    "print(torch_w2.grad)\n",
    "print(w2.grad)\n",
    "print(torch_c1.grad)\n",
    "print(c1.grad)\n",
    "print(torch_c2.grad)\n",
    "print(c2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "9477e9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996045562816742"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Neuron:\n",
    "    \n",
    "    def __init__(self, no_of_inputs):\n",
    "        self.w = [Node(random.uniform(-1,1)) for _ in range(no_of_inputs)]\n",
    "        self.b = Node(random.uniform(-1,1))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        s = sum([wi * xi for wi, xi in zip(self.w,x)], self.b)\n",
    "        return s.tanh()\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "    \n",
    "x = [2.0, -4.0]\n",
    "n = Neuron(2)\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "7d32027e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.011420588370786336, 0.26380179097884005, 0.9995642255834293]"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Layer:\n",
    "    \n",
    "    def __init__(self, in_nodes, out_nodes):\n",
    "        self.neurons = [Neuron(in_nodes) for _ in range(out_nodes)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return [n(x) for n in self.neurons]\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "x = [2.0, -4.0]\n",
    "n = Layer(2, 3)\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "3797ddd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.45161691216228605]"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP:\n",
    "    \n",
    "    def __init__(self, in_nodes, layer_specs):\n",
    "        sizes = [in_nodes] + layer_specs\n",
    "        self.layers = [Layer(sizes[i], sizes[i+1]) for i in range(len(layer_specs))]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "x = [2.0, -4.0, 6.0]\n",
    "n = MLP(3, [4,4,1])\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "f99bacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the neural Network\n",
    "\n",
    "X = [[2.0,4.0,-8.0],\n",
    "     [-6.0,3.0,5.0],\n",
    "     [7.0,2.0,7.0],\n",
    "     [8.0,9.0,-4.0]]\n",
    "Y = [1.0, -1.0, -1.0, 1.0]\n",
    "Y_pred = [n(x)[0] for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "12283a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6134792456102443,\n",
       " -0.39656343406800304,\n",
       " -0.1962253997132718,\n",
       " 0.3062809878475438]"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "ac601b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6408336585656964\n"
     ]
    }
   ],
   "source": [
    "loss = sum([(Y_pred[i]-Y[i])**2 for i in range(len(Y))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "bfcbb56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.layers[0].neurons[0].w[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "b5ca120f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "4282563b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.04165207639793912\n",
      "1 0.041037317466398326\n",
      "2 0.04043989657852427\n",
      "3 0.039859088291375945\n",
      "4 0.03929420770399081\n",
      "5 0.03874460760272856\n",
      "6 0.03820967585034613\n",
      "7 0.037688832994273544\n",
      "8 0.03718153007240695\n",
      "9 0.03668724659720476\n",
      "10 0.03620548870102809\n",
      "11 0.03573578742754556\n",
      "12 0.035277697155669155\n",
      "13 0.0348307941439311\n",
      "14 0.034394675184481846\n",
      "15 0.033968956357007855\n",
      "16 0.03355327187385594\n",
      "17 0.03314727300852532\n",
      "18 0.03275062710046275\n",
      "19 0.03236301662978529\n",
      "20 0.031984138356167334\n",
      "21 0.03161370251667412\n",
      "22 0.03125143207781254\n",
      "23 0.03089706203750489\n",
      "24 0.030550338773081963\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 25\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Forward pass\n",
    "    Y_pred = [n(x)[0] for x in X]\n",
    "    loss = sum([(Y_pred[i]-Y[i])**2 for i in range(len(Y))])\n",
    "    \n",
    "    # Zero-grad\n",
    "    for p in n.parameters():\n",
    "        p.grad = 0.0\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    for p in n.parameters():\n",
    "        p.val += -LEARNING_RATE * p.grad\n",
    "    \n",
    "    print(epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "71d497f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9580498923710723,\n",
       " -0.9120606451659372,\n",
       " -0.9066485246830148,\n",
       " 0.8889022989863676]"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c71e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
